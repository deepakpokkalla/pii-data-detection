seed: 461
use_wandb: false
input_data_dir: ../datasets/pii-datamix-v31
fold: 0
all_data: false
comp_multiplier: 3
outside_threshold: 0.9
save_model: true

sample_external_examples: false
external_sampling_rate: 0.15

datamix_sets:
  - nicholas
  - mpware
  - raja_v1
  - raja_v2
  - raja_v3
  - raja_v4
  - raja_v5
  - raja_v5_curated
  - raja_old

datamix_weights:
  - 0 # nicholas
  - 1 # mpware
  - 0 # raja_v1
  - 0 # raja_v2
  - 0 # raja_v3
  - 0 # raja_v4
  - 1 # raja_v5
  - 0 # raja_v5_curated
  - 1 # raja_old

model:
  backbone_path: google/gemma-2b
  max_length: 1024
  stride: 256
  num_proc: 1

  lora:
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj
    r: 32 # higher r gives nan loss
    lora_alpha: 32
    lora_dropout: 0.1
    modules_to_save:
      - classification_head

train_params:
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1 # 4
  num_train_epochs: 1 # 1
  gradient_accumulation_steps: 4
  warmup_pct: 0.1
  eval_frequency: 100
  patience: 10
  save_trigger: 0.0


optimizer:
  name: AdamW8bit
  head_lr: 1e-5
  lr: 3e-5
  weight_decay: 1e-2
  max_grad_norm: 0.3

outputs:
  model_dir: ../models/d_gemma_2b

wandb:
  project: pii-detection
  run_name: exp01-gemma-2b # exp201-gemma
  tags:
    - gemma